<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>UCSB NLP Blog - William Yang Wang</title><link href="nlp.cs.ucsb.edu/blog/" rel="alternate"></link><link href="nlp.cs.ucsb.edu/blog/feeds/william-yang-wang.atom.xml" rel="self"></link><id>nlp.cs.ucsb.edu/blog/</id><updated>2021-10-15T12:00:00-07:00</updated><entry><title>UC Santa Barbara NLP Group Recruiting Ph.D. Students for 2022!</title><link href="nlp.cs.ucsb.edu/blog/uc-santa-barbara-nlp-group-recruiting-phd-students-for-2022.html" rel="alternate"></link><published>2021-10-15T12:00:00-07:00</published><updated>2021-10-15T12:00:00-07:00</updated><author><name>William Yang Wang</name></author><id>tag:None,2021-10-15:nlp.cs.ucsb.edu/blog/uc-santa-barbara-nlp-group-recruiting-phd-students-for-2022.html</id><summary type="html">&lt;p&gt;Come join us at the UCSB NLP Group as a new Ph.D. student!&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Multiple Ph.D. Positions in NLP/AI/ML at UCSB!&lt;/h3&gt;
&lt;p&gt;!Fig!8!
&lt;img alt="zero-shot-fact-verification" class="img-fluid" src="images/ucsb_aerial.jpg"&gt;
Come join us at the UCSB NLP Group as a new Ph.D. student!&lt;/p&gt;
&lt;p&gt;The Computer Science Department at University of California, Santa Barbara invites applications for multiple PhD student positions in Natural Language Processing, Artificial Intelligence, and Machine Learning. &lt;a href="http://nlp.cs.ucsb.edu"&gt;UCSB Natural Language Processing Group&lt;/a&gt; includes Profs. &lt;a href="https://code-terminator.github.io/"&gt;Shiyu Chang&lt;/a&gt;, &lt;a href="https://lileicc.github.io/"&gt;Lei Li&lt;/a&gt;, &lt;a href="https://sjtodd.github.io/"&gt;Simon Todd&lt;/a&gt;, &lt;a href="https://sites.cs.ucsb.edu/~william/"&gt;William Wang&lt;/a&gt;, and &lt;a href="https://sites.cs.ucsb.edu/~xyan/"&gt;Xifeng Yan&lt;/a&gt;. &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;We are looking for students who are:&lt;/strong&gt; &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Self-motivated&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Passionate about advancing AI&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Proficienct programmers and problem solvers&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Mathematically mature and proficient in ML-relevant statistical methods&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Familiar with deep learning frameworks such as TensorFlow, PyTorch, or MXNet.&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;UC Santa Barbara is a &lt;a href="https://www.news.ucsb.edu/2021/020393/top-five"&gt;Top 5 U.S. Public Research University&lt;/a&gt;&lt;/strong&gt;, and &lt;a href="http://csrankings.org/"&gt;the UCSB NLP Group ranked #4 in the most productive NLP groups in 2018-2021 in America&lt;/a&gt;. Recent UCSB CS and NLP PhD graduates and postdocs have taken tenure-track faculty positions at prestigious schools such as UIUC, UCSD, Waterloo, UChicago, UT Austin, UMich, Dartmouth, Purdue, Virginia Tech, OSU, UCSC, Northeastern, and Rochester. Our PhD students were placed into top industry internship positions during Summer, including Facebook AI Research, Google AI, Microsoft Research, Salesforce, Amazon etc. UCSB boasts to be &lt;a href="https://vimeo.com/106330614"&gt;one of the most beautiful campuses in the world&lt;/a&gt; with perfect weather year round. &lt;/p&gt;
&lt;p&gt;UCSB’s international scholar office will provide support for visa, and we will provide top academic PhD student salary, health insurance, benefits, and travel budget for conferences. Qualified candidates may directly apply to UCSB’s CS PhD program and indicate faculty of interest in the personal statement and the application system. &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;PLEASE NOTE: The UCSB Computer Science department has eliminated the GRE requirement for Fall 2022 applicants.&lt;/strong&gt; &lt;a href="https://cs.ucsb.edu/education/graduate/overview"&gt;More information&lt;/a&gt;.&lt;/p&gt;</content><category term="Announcements"></category><category term="news"></category><category term="about"></category></entry><entry><title>Investigating Memorization of Conspiracy Theories in Text Generation</title><link href="nlp.cs.ucsb.edu/blog/investigating-memorization-of-conspiracy-theories-in-text-generation.html" rel="alternate"></link><published>2021-08-02T21:01:00-07:00</published><updated>2021-08-02T21:01:00-07:00</updated><author><name>Sharon Levy</name></author><id>tag:None,2021-08-02:nlp.cs.ucsb.edu/blog/investigating-memorization-of-conspiracy-theories-in-text-generation.html</id><summary type="html">&lt;p&gt;Regarding neural natural language generation models may propagate conspiracy theories by memorization from Findings of ACL 2021.&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Overview&lt;/h3&gt;
&lt;p&gt;What do language models memorize? As the creation and adoption of natural language generation (NLG) models increases, questions arise regarding the information these models learn. While it is known that NLG models produce biased and harmful text, most studies do not evaluate what leads to these generations: memorization of training data. &lt;/p&gt;
&lt;p&gt;In our ACL 2021 Findings &lt;a href="https://aclanthology.org/2021.findings-acl.416/"&gt;paper&lt;/a&gt;, we aim to determine the extent to which GPT-2 (and other language models) memorizes and generates harmful information. Unlike previous studies, we perform our analysis &lt;strong&gt;without access to the model's training data&lt;/strong&gt;. While this makes the task of detecting memorized data more difficult, it allows our methods to generalize to models that do not release their large-scale training sets alongside published models. Additionally, we perform our analysis with regards to a particularly dangerous type of misinformation: conspiracy theories. &lt;/p&gt;
&lt;p&gt;We propose methods to evaluate the memorization of this text, through various model settings and linguistic analysis. &lt;/p&gt;
&lt;h3&gt;Memorization in NLG Models&lt;/h3&gt;
&lt;p&gt;In general, generated text can be broken down into three categories:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Memorized: generated text with exact matches existing within the training data.&lt;/li&gt;
&lt;li&gt;Generalized: generations that do not have exact matches in the data but produce text that follows the same ideas as those in the training data.&lt;/li&gt;
&lt;li&gt;Hallucinated: generations about topics that are neither factually correct nor follow any of the existing conspiracy theories surrounding the topic&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Most studies either evaluate memorized vs. generalized text or group memorized and generalized text together to evaluate against hallucinated text. As distinguishing among these three categories without access to training data is exceptionally difficult, we consider both memorized and generalized text as "memorized".&lt;/p&gt;
&lt;h3&gt;Varying Model Settings&lt;/h3&gt;
&lt;h4&gt;Human Evaluation&lt;/h4&gt;
&lt;p&gt;Two simple model parameters to evaluate are model size and temperature. To proceed with our analysis, we create a dataset of 17 well-known conspiracy theory topics and generic prompts for each to feed into the model. These are prompts such as "The Earth is" and "The Holocaust is". In order to determine whether a piece of generated text affirms or states a conspiracy theory as fact, we crowdsource with an additional layer of manual inspection. Our findings show that reducing model size drastically lowers the capacity for GPT-2 to retain information about well-known conspiracy theories, as seen in Figure 1. &lt;/p&gt;
&lt;p&gt;!Fig!5!
&lt;img alt="Percentage of conspiracy theories generated by GPT-2 models of size small, medium, and large when prompted on 17 different conspiracy theory topics. Each topic is used to generate 20 sequences for a total of 340 generations." class="img-fluid" src="images/2108/size.png"&gt;
Percentage of conspiracy theories generated by GPT-2 models of size small, medium, and large when prompted on 17 different conspiracy theory topics. Each topic is used to generate 20 sequences for a total of 340 generations.&lt;/p&gt;
&lt;p&gt;We further evaluate changes in temperature while controlling for model size. By decreasing the temperature during generation, we are able to reduce randomness in the model's outputs. We can then analyze the curve of produced conspiracy theories and discover the topics for which the model has deeply memorized conspiracy theories (Figure 2).&lt;/p&gt;
&lt;p&gt;!Fig!5!
&lt;img alt="Percentage of conspiracy theories generated by GPT-2 Large at varying temperatures when prompted on 17 different conspiracy theory topics. Each topic is used to generate 20 sequences for a total of 340 generations." class="img-fluid" src="images/2108/temperature.png"&gt;
Percentage of conspiracy theories generated by GPT-2 Large at varying temperatures when prompted on 17 different conspiracy theory topics. Each topic is used to generate 20 sequences for a total of 340 generations.&lt;/p&gt;
&lt;h4&gt;Automated Evaluation&lt;/h4&gt;
&lt;p&gt;Performing human evaluation while probing for model memorization is not necessarily efficient. Therefore, we take steps to automatically evaluate NLG models for the memorization and generation of conspiracy theories. To do this we:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Generate several thousand sequences of text with the prompt "The conspiracy theory is that" and extract the generated text without the prompt at different temperature settings.&lt;/li&gt;
&lt;li&gt;Calculate the BLEU score for each generated sequence against the first page of Google search results for the text.&lt;/li&gt;
&lt;li&gt;Calculate the perplexity of each generated sequence for each GPT-2 model size.&lt;/li&gt;
&lt;li&gt;Compute the correlation of the BLEU Google results scores with GPT-2 perplexity.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;!Fig!5!
&lt;img alt="Spearman correlation of model perplexity vs. Google search BLEU score for GPT-2 generated conspiracy theories across varying temperature settings. Each generated theory is evaluated against the first page of Google search results with the BLEU metric." class="img-fluid" src="images/2108/automated.png"&gt;
Spearman correlation of model perplexity vs. Google search BLEU score for GPT-2 generated conspiracy theories across varying temperature settings. Each generated theory is evaluated against the first page of Google search results with the BLEU metric.&lt;/p&gt;
&lt;p&gt;Our results can be seen in Figure 3. These follow our human evaluation results and show a strong relationship between a generated conspiracy theory’s perplexity and its appearance in Google search results for larger model sizes and lower temperatures. This can allow future research to move towards the creation of automated evaluation metrics for difficult tasks such as text memorization.&lt;/p&gt;
&lt;h3&gt;Linguistic Analysis&lt;/h3&gt;
&lt;p&gt;In addition to evaluating how different model settings affect the generation of memorized conspiracy theories, we further investigate whether we find any patterns among different linguistic properties in our generated sequences. Figures 4 and 5 show results for sentiment analysis and linguistic diversity (with BERTScore), respectively. &lt;/p&gt;
&lt;p&gt;!Fig!5!
&lt;img alt="Comparison of average sentiment scores across GPT-2 Large generated conspiracy theories with the DistilBERT (dBERT), VADER, and TextBlob sentiment classifiers along with the Wilcoxon rank-sum p-values for generation pairs of temperature 0.4 and 1. The conspiracy theories are generated at the temperature values of 0.4, 0.7, and 1.0 and sentiment scores range from -1 to 1." class="img-fluid" src="images/2108/sentiment.png"&gt;
Comparison of average sentiment scores across GPT-2 Large generated conspiracy theories with the DistilBERT (dBERT), VADER, and TextBlob sentiment classifiers along with the Wilcoxon rank-sum p-values for generation pairs of temperature 0.4 and 1. The conspiracy theories are generated at the temperature values of 0.4, 0.7, and 1.0 and sentiment scores range from -1 to 1.&lt;/p&gt;
&lt;p&gt;!Fig!5!
&lt;img alt="Comparison of average BERTScore values across Wikipedia topic-prompted GPT-2 generations for varying model sizes and temperatures. Generations for each size-temperature pair are evaluated against other generations for their specific topic. Wilcoxon rank-sum p-values for the large-small model pairs at each temperature are listed at the bottom." class="img-fluid" src="images/2108/diversity.png"&gt;
Comparison of average BERTScore values across Wikipedia topic-prompted GPT-2 generations for varying model sizes and temperatures. Generations for each size-temperature pair are evaluated against other generations for their specific topic. Wilcoxon rank-sum p-values for the large-small model pairs at each temperature are listed at the bottom.&lt;/p&gt;
&lt;p&gt;When analyzing these two properties against various model settings, we learn:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;All three sentiment analysis models exhibit the same downward trend among score and temperature values. As such, the generated texts at these lower temperature levels are associated with strong negative emotions.&lt;/li&gt;
&lt;li&gt;As the temperature increases and model size decreases, the textual similarity across generations for each topic decreases. This further confirms our human evaluated results of more memorization at larger model sizes, which allows for the generation of contextually aligned outputs for specific topics.&lt;/li&gt;
&lt;/ol&gt;
&lt;h3&gt;Moving Forward&lt;/h3&gt;
&lt;p&gt;In our work, we study the generation of harmful text in NLG models. This behavior  can be traced to the memorization of training data and as such, we outline a few steps that can be taken to reduce this harm.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Clean datasets of misinformation and biases before training.&lt;/li&gt;
&lt;li&gt;Supplementing the existing dataset with a smaller "clean" dataset to oversample truthful/non-harmful information.&lt;/li&gt;
&lt;li&gt;Restrict model size.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;While each of these has its drawbacks (such as lower generation quality), the general minimization of harmful generation is of great importance and should be accounted for in future models.&lt;/p&gt;</content><category term="ACL 2021"></category><category term="Language generation"></category><category term="conspiracy theories"></category><category term="fairness"></category></entry></feed>